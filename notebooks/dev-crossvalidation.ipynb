{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models import create_mlp_model\n",
    "from cross_validation import CV_Skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data set just for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "# create the sparse target\n",
    "y_sparse = to_categorical(y)\n",
    "\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sparse[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=17, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=17, shuffle=True)\n",
    "\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preproc method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scl_factor = StandardScaler()\n",
    "\n",
    "print(scl_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_neurons      = 5\n",
    "output_layer_neurons      = 3\n",
    "number_of_hidden_layers   = 1\n",
    "hidden_layer_act_function = 'relu'\n",
    "output_layer_act_function = 'softmax'\n",
    "loss_function             = 'categorical_crossentropy'\n",
    "optimizer                 = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/micaelverissimo/anaconda3/envs/my_devs/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "cv_test_model = create_mlp_model(input_dim=X.shape[1], output_dim=output_layer_neurons,\n",
    "                         n_neurons=hidden_layer_neurons, n_layers=number_of_hidden_layers,\n",
    "                         hl_act_func=hidden_layer_act_function,\n",
    "                         ol_act_func=output_layer_act_function,\n",
    "                         loss_func=loss_function,\n",
    "                         optimizer=optimizer,\n",
    "                         name='test_model'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cv_test_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust some tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_params = {'n_inits'   : 2,\n",
    "           'batch_size' : 50,\n",
    "           'epochs'     : 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test = CV_Skeleton(X, y, \n",
    "                      tuning_params=t_params,\n",
    "                      preproc_method=scl_factor,\n",
    "                      cv_method=skf,\n",
    "                      ml_model=cv_test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we make the cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in the Fold: 1 | Init: 1\n",
      "WARNING:tensorflow:From /home/micaelverissimo/anaconda3/envs/my_devs/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9463 - acc: 0.5778 - val_loss: 0.8899 - val_acc: 0.7333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 57us/step - loss: 0.9393 - acc: 0.5926 - val_loss: 0.8830 - val_acc: 0.7333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 127us/step - loss: 0.9320 - acc: 0.5926 - val_loss: 0.8758 - val_acc: 0.7333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 126us/step - loss: 0.9246 - acc: 0.6000 - val_loss: 0.8684 - val_acc: 0.7333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 138us/step - loss: 0.9172 - acc: 0.6222 - val_loss: 0.8611 - val_acc: 0.7333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 122us/step - loss: 0.9099 - acc: 0.6222 - val_loss: 0.8538 - val_acc: 0.7333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 83us/step - loss: 0.9027 - acc: 0.6593 - val_loss: 0.8468 - val_acc: 0.7333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 143us/step - loss: 0.8956 - acc: 0.6667 - val_loss: 0.8400 - val_acc: 0.7333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 84us/step - loss: 0.8888 - acc: 0.6667 - val_loss: 0.8332 - val_acc: 0.7333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 116us/step - loss: 0.8819 - acc: 0.6741 - val_loss: 0.8266 - val_acc: 0.7333\n",
      "Training in the Fold: 1 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 2.0339 - acc: 0.2222 - val_loss: 1.9305 - val_acc: 0.0667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 103us/step - loss: 2.0154 - acc: 0.2148 - val_loss: 1.9131 - val_acc: 0.0667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 96us/step - loss: 1.9945 - acc: 0.2222 - val_loss: 1.8936 - val_acc: 0.0667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 91us/step - loss: 1.9699 - acc: 0.2222 - val_loss: 1.8736 - val_acc: 0.0667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 73us/step - loss: 1.9465 - acc: 0.2148 - val_loss: 1.8533 - val_acc: 0.0667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 175us/step - loss: 1.9206 - acc: 0.2000 - val_loss: 1.8333 - val_acc: 0.0667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 139us/step - loss: 1.8968 - acc: 0.2000 - val_loss: 1.8137 - val_acc: 0.0667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 71us/step - loss: 1.8737 - acc: 0.2000 - val_loss: 1.7944 - val_acc: 0.0667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 62us/step - loss: 1.8502 - acc: 0.2000 - val_loss: 1.7758 - val_acc: 0.0667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.8261 - acc: 0.2074 - val_loss: 1.7580 - val_acc: 0.0667\n",
      "Training in the Fold: 2 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 87us/step - loss: 1.1658 - acc: 0.3333 - val_loss: 1.1364 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 166us/step - loss: 1.1661 - acc: 0.3630 - val_loss: 1.1350 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.1634 - acc: 0.3630 - val_loss: 1.1315 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 106us/step - loss: 1.1590 - acc: 0.3556 - val_loss: 1.1267 - val_acc: 0.4667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 107us/step - loss: 1.1533 - acc: 0.3630 - val_loss: 1.1211 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 118us/step - loss: 1.1470 - acc: 0.3704 - val_loss: 1.1149 - val_acc: 0.4667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 97us/step - loss: 1.1405 - acc: 0.3704 - val_loss: 1.1084 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 1.1327 - acc: 0.3778 - val_loss: 1.1020 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 80us/step - loss: 1.1258 - acc: 0.3778 - val_loss: 1.0954 - val_acc: 0.4667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 84us/step - loss: 1.1193 - acc: 0.3704 - val_loss: 1.0888 - val_acc: 0.4667\n",
      "Training in the Fold: 2 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 77us/step - loss: 1.3557 - acc: 0.3333 - val_loss: 1.3507 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 100us/step - loss: 1.3517 - acc: 0.3333 - val_loss: 1.3443 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 104us/step - loss: 1.3431 - acc: 0.3333 - val_loss: 1.3347 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 152us/step - loss: 1.3318 - acc: 0.3333 - val_loss: 1.3230 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 125us/step - loss: 1.3186 - acc: 0.3333 - val_loss: 1.3099 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 76us/step - loss: 1.3043 - acc: 0.3333 - val_loss: 1.2961 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 69us/step - loss: 1.2897 - acc: 0.3407 - val_loss: 1.2819 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 99us/step - loss: 1.2747 - acc: 0.3481 - val_loss: 1.2676 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 104us/step - loss: 1.2597 - acc: 0.3481 - val_loss: 1.2534 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 56us/step - loss: 1.2456 - acc: 0.3481 - val_loss: 1.2394 - val_acc: 0.3333\n",
      "Training in the Fold: 3 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 127us/step - loss: 0.8677 - acc: 0.5037 - val_loss: 0.9830 - val_acc: 0.4667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.8630 - acc: 0.5185 - val_loss: 0.9769 - val_acc: 0.4667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 79us/step - loss: 0.8574 - acc: 0.5185 - val_loss: 0.9698 - val_acc: 0.4667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 74us/step - loss: 0.8508 - acc: 0.5185 - val_loss: 0.9622 - val_acc: 0.4667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 144us/step - loss: 0.8441 - acc: 0.5259 - val_loss: 0.9542 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 125us/step - loss: 0.8368 - acc: 0.5407 - val_loss: 0.9460 - val_acc: 0.4667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 81us/step - loss: 0.8294 - acc: 0.5407 - val_loss: 0.9377 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 0.8222 - acc: 0.5407 - val_loss: 0.9294 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 0.8147 - acc: 0.5630 - val_loss: 0.9214 - val_acc: 0.5333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 106us/step - loss: 0.8076 - acc: 0.5778 - val_loss: 0.9133 - val_acc: 0.5333\n",
      "Training in the Fold: 3 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 173us/step - loss: 0.9124 - acc: 0.7407 - val_loss: 0.8642 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 133us/step - loss: 0.9096 - acc: 0.7481 - val_loss: 0.8599 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 126us/step - loss: 0.9053 - acc: 0.7556 - val_loss: 0.8543 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 97us/step - loss: 0.8992 - acc: 0.7630 - val_loss: 0.8480 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 95us/step - loss: 0.8929 - acc: 0.7778 - val_loss: 0.8410 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 133us/step - loss: 0.8851 - acc: 0.7852 - val_loss: 0.8337 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 161us/step - loss: 0.8780 - acc: 0.7852 - val_loss: 0.8259 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 103us/step - loss: 0.8699 - acc: 0.7852 - val_loss: 0.8182 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 130us/step - loss: 0.8613 - acc: 0.7852 - val_loss: 0.8106 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 84us/step - loss: 0.8532 - acc: 0.7926 - val_loss: 0.8029 - val_acc: 0.8667\n",
      "Training in the Fold: 4 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 87us/step - loss: 1.5249 - acc: 0.0296 - val_loss: 1.4345 - val_acc: 0.0667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 1.5176 - acc: 0.0370 - val_loss: 1.4217 - val_acc: 0.0667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 82us/step - loss: 1.5032 - acc: 0.0444 - val_loss: 1.4036 - val_acc: 0.0667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 1.4843 - acc: 0.0519 - val_loss: 1.3823 - val_acc: 0.0667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 117us/step - loss: 1.4623 - acc: 0.0741 - val_loss: 1.3591 - val_acc: 0.0667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 104us/step - loss: 1.4388 - acc: 0.0741 - val_loss: 1.3353 - val_acc: 0.0667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 112us/step - loss: 1.4150 - acc: 0.0889 - val_loss: 1.3111 - val_acc: 0.0667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 64us/step - loss: 1.3909 - acc: 0.1111 - val_loss: 1.2858 - val_acc: 0.1333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.3662 - acc: 0.1111 - val_loss: 1.2609 - val_acc: 0.2000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 69us/step - loss: 1.3417 - acc: 0.1481 - val_loss: 1.2369 - val_acc: 0.2667\n",
      "Training in the Fold: 4 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 103us/step - loss: 1.1898 - acc: 0.3852 - val_loss: 1.1946 - val_acc: 0.4667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 83us/step - loss: 1.1797 - acc: 0.3852 - val_loss: 1.1826 - val_acc: 0.4667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 104us/step - loss: 1.1668 - acc: 0.3852 - val_loss: 1.1683 - val_acc: 0.4667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 127us/step - loss: 1.1520 - acc: 0.3852 - val_loss: 1.1527 - val_acc: 0.4667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 66us/step - loss: 1.1378 - acc: 0.3852 - val_loss: 1.1364 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 86us/step - loss: 1.1209 - acc: 0.3852 - val_loss: 1.1205 - val_acc: 0.4667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 71us/step - loss: 1.1054 - acc: 0.3852 - val_loss: 1.1047 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 70us/step - loss: 1.0902 - acc: 0.3852 - val_loss: 1.0892 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 74us/step - loss: 1.0758 - acc: 0.3852 - val_loss: 1.0741 - val_acc: 0.4667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 57us/step - loss: 1.0605 - acc: 0.3852 - val_loss: 1.0597 - val_acc: 0.4667\n",
      "Training in the Fold: 5 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 157us/step - loss: 1.0306 - acc: 0.2963 - val_loss: 1.0356 - val_acc: 0.2667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 102us/step - loss: 1.0175 - acc: 0.2963 - val_loss: 1.0201 - val_acc: 0.2667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 97us/step - loss: 1.0018 - acc: 0.3407 - val_loss: 1.0032 - val_acc: 0.2667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 167us/step - loss: 0.9857 - acc: 0.3778 - val_loss: 0.9858 - val_acc: 0.2667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 101us/step - loss: 0.9693 - acc: 0.3852 - val_loss: 0.9683 - val_acc: 0.2667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 115us/step - loss: 0.9526 - acc: 0.4148 - val_loss: 0.9512 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 98us/step - loss: 0.9366 - acc: 0.4444 - val_loss: 0.9348 - val_acc: 0.4000\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 87us/step - loss: 0.9210 - acc: 0.4741 - val_loss: 0.9192 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 235us/step - loss: 0.9062 - acc: 0.5037 - val_loss: 0.9043 - val_acc: 0.4000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 107us/step - loss: 0.8917 - acc: 0.5259 - val_loss: 0.8901 - val_acc: 0.5333\n",
      "Training in the Fold: 5 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 67us/step - loss: 1.3077 - acc: 0.3111 - val_loss: 1.3718 - val_acc: 0.2667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 76us/step - loss: 1.3009 - acc: 0.3185 - val_loss: 1.3617 - val_acc: 0.2667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 68us/step - loss: 1.2890 - acc: 0.3111 - val_loss: 1.3475 - val_acc: 0.2667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 72us/step - loss: 1.2721 - acc: 0.3111 - val_loss: 1.3313 - val_acc: 0.2667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.2533 - acc: 0.3037 - val_loss: 1.3140 - val_acc: 0.2667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 76us/step - loss: 1.2347 - acc: 0.3111 - val_loss: 1.2946 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 147us/step - loss: 1.2154 - acc: 0.3333 - val_loss: 1.2737 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 73us/step - loss: 1.1952 - acc: 0.3481 - val_loss: 1.2531 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 82us/step - loss: 1.1750 - acc: 0.3481 - val_loss: 1.2331 - val_acc: 0.2667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 100us/step - loss: 1.1564 - acc: 0.3630 - val_loss: 1.2134 - val_acc: 0.2667\n",
      "Training in the Fold: 6 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 94us/step - loss: 1.2452 - acc: 0.1481 - val_loss: 1.2800 - val_acc: 0.0667\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.2468 - acc: 0.1481 - val_loss: 1.2787 - val_acc: 0.0667\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 187us/step - loss: 1.2445 - acc: 0.1481 - val_loss: 1.2743 - val_acc: 0.0667\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 108us/step - loss: 1.2399 - acc: 0.1481 - val_loss: 1.2676 - val_acc: 0.0667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 87us/step - loss: 1.2333 - acc: 0.1481 - val_loss: 1.2596 - val_acc: 0.0667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 69us/step - loss: 1.2259 - acc: 0.1630 - val_loss: 1.2505 - val_acc: 0.0667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 139us/step - loss: 1.2178 - acc: 0.1630 - val_loss: 1.2408 - val_acc: 0.0667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 72us/step - loss: 1.2090 - acc: 0.1630 - val_loss: 1.2308 - val_acc: 0.0667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 75us/step - loss: 1.1997 - acc: 0.1778 - val_loss: 1.2207 - val_acc: 0.0667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 100us/step - loss: 1.1906 - acc: 0.1778 - val_loss: 1.2104 - val_acc: 0.0667\n",
      "Training in the Fold: 6 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 97us/step - loss: 1.4580 - acc: 0.4074 - val_loss: 1.4236 - val_acc: 0.5333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 80us/step - loss: 1.4441 - acc: 0.4074 - val_loss: 1.3988 - val_acc: 0.5333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 55us/step - loss: 1.4174 - acc: 0.4000 - val_loss: 1.3663 - val_acc: 0.5333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 85us/step - loss: 1.3840 - acc: 0.3926 - val_loss: 1.3295 - val_acc: 0.5333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 72us/step - loss: 1.3474 - acc: 0.3778 - val_loss: 1.2907 - val_acc: 0.5333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.3109 - acc: 0.3852 - val_loss: 1.2511 - val_acc: 0.5333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 117us/step - loss: 1.2724 - acc: 0.3778 - val_loss: 1.2124 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 75us/step - loss: 1.2349 - acc: 0.3778 - val_loss: 1.1751 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 160us/step - loss: 1.2004 - acc: 0.3778 - val_loss: 1.1391 - val_acc: 0.4667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 68us/step - loss: 1.1673 - acc: 0.3778 - val_loss: 1.1047 - val_acc: 0.4667\n",
      "Training in the Fold: 7 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 55us/step - loss: 1.2493 - acc: 0.3407 - val_loss: 1.2679 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 112us/step - loss: 1.2482 - acc: 0.2444 - val_loss: 1.2650 - val_acc: 0.1333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 93us/step - loss: 1.2451 - acc: 0.1852 - val_loss: 1.2604 - val_acc: 0.1333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 95us/step - loss: 1.2406 - acc: 0.1852 - val_loss: 1.2549 - val_acc: 0.1333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 115us/step - loss: 1.2357 - acc: 0.1852 - val_loss: 1.2485 - val_acc: 0.1333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 107us/step - loss: 1.2294 - acc: 0.1926 - val_loss: 1.2417 - val_acc: 0.1333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 82us/step - loss: 1.2229 - acc: 0.2000 - val_loss: 1.2347 - val_acc: 0.1333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 77us/step - loss: 1.2161 - acc: 0.2074 - val_loss: 1.2273 - val_acc: 0.1333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 111us/step - loss: 1.2091 - acc: 0.2074 - val_loss: 1.2201 - val_acc: 0.1333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 1.2017 - acc: 0.2296 - val_loss: 1.2129 - val_acc: 0.1333\n",
      "Training in the Fold: 7 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 94us/step - loss: 1.0702 - acc: 0.4074 - val_loss: 1.0537 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 65us/step - loss: 1.0651 - acc: 0.4148 - val_loss: 1.0474 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 51us/step - loss: 1.0586 - acc: 0.4222 - val_loss: 1.0396 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 57us/step - loss: 1.0505 - acc: 0.4296 - val_loss: 1.0310 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 86us/step - loss: 1.0421 - acc: 0.4370 - val_loss: 1.0219 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 81us/step - loss: 1.0331 - acc: 0.4444 - val_loss: 1.0126 - val_acc: 0.4667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 98us/step - loss: 1.0239 - acc: 0.4593 - val_loss: 1.0032 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 52us/step - loss: 1.0146 - acc: 0.4815 - val_loss: 0.9938 - val_acc: 0.5333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 93us/step - loss: 1.0055 - acc: 0.4889 - val_loss: 0.9845 - val_acc: 0.5333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.9964 - acc: 0.5259 - val_loss: 0.9752 - val_acc: 0.5333\n",
      "Training in the Fold: 8 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 101us/step - loss: 1.1440 - acc: 0.4000 - val_loss: 1.1109 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 108us/step - loss: 1.1391 - acc: 0.3481 - val_loss: 1.1073 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 95us/step - loss: 1.1333 - acc: 0.3407 - val_loss: 1.1032 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 86us/step - loss: 1.1265 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 81us/step - loss: 1.1198 - acc: 0.3407 - val_loss: 1.0942 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 116us/step - loss: 1.1131 - acc: 0.3481 - val_loss: 1.0894 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 99us/step - loss: 1.1058 - acc: 0.3852 - val_loss: 1.0846 - val_acc: 0.4000\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 74us/step - loss: 1.0988 - acc: 0.3926 - val_loss: 1.0799 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 122us/step - loss: 1.0918 - acc: 0.4000 - val_loss: 1.0752 - val_acc: 0.4000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 1.0854 - acc: 0.4074 - val_loss: 1.0705 - val_acc: 0.4000\n",
      "Training in the Fold: 8 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 96us/step - loss: 1.4220 - acc: 0.2741 - val_loss: 1.2919 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 118us/step - loss: 1.4151 - acc: 0.1407 - val_loss: 1.2859 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 128us/step - loss: 1.4061 - acc: 0.1481 - val_loss: 1.2790 - val_acc: 0.2000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 120us/step - loss: 1.3954 - acc: 0.1481 - val_loss: 1.2714 - val_acc: 0.2000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 123us/step - loss: 1.3841 - acc: 0.1481 - val_loss: 1.2634 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 104us/step - loss: 1.3727 - acc: 0.1556 - val_loss: 1.2553 - val_acc: 0.2000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 108us/step - loss: 1.3607 - acc: 0.1704 - val_loss: 1.2471 - val_acc: 0.2000\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 105us/step - loss: 1.3486 - acc: 0.1704 - val_loss: 1.2389 - val_acc: 0.2667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 107us/step - loss: 1.3371 - acc: 0.1852 - val_loss: 1.2309 - val_acc: 0.2667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 80us/step - loss: 1.3256 - acc: 0.1852 - val_loss: 1.2230 - val_acc: 0.2667\n",
      "Training in the Fold: 9 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 103us/step - loss: 1.2551 - acc: 0.3333 - val_loss: 1.3946 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 115us/step - loss: 1.2465 - acc: 0.3333 - val_loss: 1.3832 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 123us/step - loss: 1.2368 - acc: 0.3333 - val_loss: 1.3699 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 117us/step - loss: 1.2254 - acc: 0.3333 - val_loss: 1.3560 - val_acc: 0.2667\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 153us/step - loss: 1.2138 - acc: 0.3333 - val_loss: 1.3417 - val_acc: 0.2667\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 120us/step - loss: 1.2016 - acc: 0.3333 - val_loss: 1.3274 - val_acc: 0.2667\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 124us/step - loss: 1.1891 - acc: 0.3333 - val_loss: 1.3132 - val_acc: 0.2667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 97us/step - loss: 1.1772 - acc: 0.3407 - val_loss: 1.2993 - val_acc: 0.2667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 86us/step - loss: 1.1656 - acc: 0.3259 - val_loss: 1.2856 - val_acc: 0.2000\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 110us/step - loss: 1.1544 - acc: 0.3185 - val_loss: 1.2722 - val_acc: 0.2000\n",
      "Training in the Fold: 9 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 108us/step - loss: 1.1229 - acc: 0.2889 - val_loss: 1.0923 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 118us/step - loss: 1.1215 - acc: 0.2889 - val_loss: 1.0897 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 177us/step - loss: 1.1179 - acc: 0.2889 - val_loss: 1.0857 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 1.1129 - acc: 0.2889 - val_loss: 1.0810 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 108us/step - loss: 1.1070 - acc: 0.3037 - val_loss: 1.0756 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 113us/step - loss: 1.1002 - acc: 0.3037 - val_loss: 1.0702 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 118us/step - loss: 1.0931 - acc: 0.3037 - val_loss: 1.0647 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 72us/step - loss: 1.0856 - acc: 0.3111 - val_loss: 1.0594 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 1.0784 - acc: 0.3111 - val_loss: 1.0540 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 81us/step - loss: 1.0710 - acc: 0.3111 - val_loss: 1.0486 - val_acc: 0.3333\n",
      "Training in the Fold: 10 | Init: 1\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 57us/step - loss: 1.0432 - acc: 0.4741 - val_loss: 1.0641 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 89us/step - loss: 1.0401 - acc: 0.4741 - val_loss: 1.0600 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 82us/step - loss: 1.0364 - acc: 0.4815 - val_loss: 1.0553 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 64us/step - loss: 1.0319 - acc: 0.4815 - val_loss: 1.0500 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 83us/step - loss: 1.0267 - acc: 0.4741 - val_loss: 1.0445 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 185us/step - loss: 1.0215 - acc: 0.4741 - val_loss: 1.0388 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 73us/step - loss: 1.0159 - acc: 0.4667 - val_loss: 1.0330 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 135us/step - loss: 1.0105 - acc: 0.4667 - val_loss: 1.0272 - val_acc: 0.4667\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 87us/step - loss: 1.0049 - acc: 0.4741 - val_loss: 1.0213 - val_acc: 0.4667\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 69us/step - loss: 0.9994 - acc: 0.4741 - val_loss: 1.0155 - val_acc: 0.4667\n",
      "Training in the Fold: 10 | Init: 2\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 52us/step - loss: 1.3606 - acc: 0.3333 - val_loss: 1.3429 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 99us/step - loss: 1.3568 - acc: 0.3259 - val_loss: 1.3368 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 101us/step - loss: 1.3483 - acc: 0.3185 - val_loss: 1.3268 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 90us/step - loss: 1.3367 - acc: 0.3185 - val_loss: 1.3142 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 110us/step - loss: 1.3221 - acc: 0.3185 - val_loss: 1.3004 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 99us/step - loss: 1.3072 - acc: 0.3185 - val_loss: 1.2857 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 113us/step - loss: 1.2911 - acc: 0.3185 - val_loss: 1.2707 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 121us/step - loss: 1.2751 - acc: 0.3185 - val_loss: 1.2560 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 81us/step - loss: 1.2600 - acc: 0.3185 - val_loss: 1.2413 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 98us/step - loss: 1.2440 - acc: 0.3111 - val_loss: 1.2275 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "cv_test.cv_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results of cross-validation\n",
    "result_dict = cv_test.get_cv_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trn_tst_indices', 'history', 'weights'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.7607583 , -0.66369814,  0.30523407, -0.11777232,  0.5637772 ],\n",
       "         [-0.68594587, -0.48333204, -0.3476057 , -0.5836633 ,  0.56206644],\n",
       "         [-0.27662924, -0.00189115, -0.7020519 ,  0.24855244, -0.03670489],\n",
       "         [ 0.7339188 ,  0.41540158,  0.61945623,  0.837243  , -0.26379085]],\n",
       "        dtype=float32),\n",
       "  array([-0.02194587, -0.02185101,  0.02808422,  0.02867591,  0.02369108],\n",
       "        dtype=float32),\n",
       "  array([[ 0.7709994 ,  0.05767832, -0.61621904],\n",
       "         [ 0.35208693, -0.55146855, -0.09618444],\n",
       "         [-0.6273001 ,  0.83503383,  0.73974013],\n",
       "         [-0.8514454 ,  0.73947996,  0.6853306 ],\n",
       "         [ 0.66307116, -0.43978062,  0.41644332]], dtype=float32),\n",
       "  array([ 0.01511719, -0.00371381, -0.01324048], dtype=float32)],\n",
       " [array([[-0.10705221,  0.01503872, -0.44918078,  0.39048067, -0.596681  ],\n",
       "         [ 0.09136633, -0.24690545,  0.40919012, -0.3970066 ,  0.60898423],\n",
       "         [-0.54943   , -0.2664579 , -0.0692044 , -0.7053366 ,  0.7464758 ],\n",
       "         [-0.22109504, -0.12426773,  0.48986065, -0.06822145, -0.58745784]],\n",
       "        dtype=float32),\n",
       "  array([-0.02757505, -0.01689345, -0.00521928,  0.00682081, -0.00187248],\n",
       "        dtype=float32),\n",
       "  array([[-0.42414024, -0.20856193, -0.18416162],\n",
       "         [-0.7714332 ,  0.3152772 , -0.7754941 ],\n",
       "         [-0.36111295, -0.18694921, -0.54793   ],\n",
       "         [ 0.14079493,  0.36750343, -0.30978712],\n",
       "         [-0.49332264, -0.87257093, -0.5794002 ]], dtype=float32),\n",
       "  array([-0.00634974, -0.01282708,  0.0161969 ], dtype=float32)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[0]['weights'], result_dict[1]['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import create_mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data set just for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 227, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 214, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 99, in init_dev\n",
      "    **args)\n",
      "  File \"pygpu/gpuarray.pyx\", line 658, in pygpu.gpuarray.init\n",
      "  File \"pygpu/gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init\n",
      "pygpu.gpuarray.GpuArrayException: b'Could not load \"libnvrtc.so\": libnvrtc.so: cannot open shared object file: No such file or directory'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "# create the sparse target\n",
    "y_sparse = to_categorical(y)\n",
    "\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sparse[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=17, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=17, shuffle=True)\n",
    "\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds 10; each fold has 2 types os indices, train and test\n"
     ]
    }
   ],
   "source": [
    "# split the data set\n",
    "train_test_indices = list(skf.split(X,y))\n",
    "print('Number of folds %i; each fold has %i types os indices, train and test' %(len(train_test_indices),\n",
    "                                                                               len(train_test_indices[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the cross-validation and make $n$ initialization in order to avoid the local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# try only a few initialization\n",
    "n_inits = 3\n",
    "# hyper-parameter for fit the model\n",
    "n_epochs = 10\n",
    "batch_size = 1024\n",
    "\n",
    "# metrics and callbacks\n",
    "metrics=[keras.metrics.sparse_top_k_categorical_accuracy, keras.metrics.categorical_accuracy]\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor='val_loss',\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=5,\n",
    "        verbose=1)\n",
    "]\n",
    "# ======== hidden layer configuration ========================\n",
    "number_of_hidden_layers = 1 # number of hidden layers in the model\n",
    "hidden_layer_neurons = 5 # hiddem layer neurons\n",
    "hidden_layer_act_function = 'relu' # the activation function\n",
    "\n",
    "# ======== output layer configuration ========================\n",
    "output_layer_neurons = 3 # there are 3 classes\n",
    "output_layer_act_function = 'softmax' # output activate function\n",
    "\n",
    "#======== compile model parameters ===========================\n",
    "optimizer = 'adam' # there are some others but this is the mostly used\n",
    "loss_function = 'categorical_crossentropy' # we have prepared the y making then sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in the Fold: 1 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 91us/step\n",
      "\n",
      "Training in the Fold: 1 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 98us/step\n",
      "\n",
      "Training in the Fold: 1 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 89us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 2 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 108us/step\n",
      "\n",
      "Training in the Fold: 2 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 169us/step\n",
      "\n",
      "Training in the Fold: 2 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 108us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 3 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 101us/step\n",
      "\n",
      "Training in the Fold: 3 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 77us/step\n",
      "\n",
      "Training in the Fold: 3 | Init: 3\n",
      "Epoch 00006: early stopping\n",
      "15/15 [==============================]15/15 [==============================] - 0s 202us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 4 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 103us/step\n",
      "\n",
      "Training in the Fold: 4 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 79us/step\n",
      "\n",
      "Training in the Fold: 4 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 96us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 5 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 85us/step\n",
      "\n",
      "Training in the Fold: 5 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 94us/step\n",
      "\n",
      "Training in the Fold: 5 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 122us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 6 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 83us/step\n",
      "\n",
      "Training in the Fold: 6 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 89us/step\n",
      "\n",
      "Training in the Fold: 6 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 81us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 7 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 142us/step\n",
      "\n",
      "Training in the Fold: 7 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 113us/step\n",
      "\n",
      "Training in the Fold: 7 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 91us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 8 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 114us/step\n",
      "\n",
      "Training in the Fold: 8 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 140us/step\n",
      "\n",
      "Training in the Fold: 8 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 113us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 9 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 112us/step\n",
      "\n",
      "Training in the Fold: 9 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 168us/step\n",
      "\n",
      "Training in the Fold: 9 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 160us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n",
      "Training in the Fold: 10 | Init: 1\n",
      "15/15 [==============================]15/15 [==============================] - 0s 96us/step\n",
      "\n",
      "Training in the Fold: 10 | Init: 2\n",
      "15/15 [==============================]15/15 [==============================] - 0s 126us/step\n",
      "\n",
      "Training in the Fold: 10 | Init: 3\n",
      "15/15 [==============================]15/15 [==============================] - 0s 105us/step\n",
      "\n",
      "~~~~~~~~~~ End the training in Fold ~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for idx, ifold in enumerate(train_test_indices):\n",
    "    train_id, test_id = ifold[0], ifold[1]\n",
    "    for init in range(n_inits):\n",
    "        print('Training in the Fold: %i | Init: %i' %(idx+1, init+1))\n",
    "        # create a scaler to prepare the data and fit using only the train data\n",
    "        scl_factor = StandardScaler()\n",
    "        scl_factor.fit(X[train_id])\n",
    "        # transform all data\n",
    "        X_norm = scl_factor.transform(X)\n",
    "        \n",
    "        # create the model\n",
    "        model = create_mlp_model(input_dim=X_norm.shape[1], output_dim=output_layer_neurons,\n",
    "                                 n_neurons=hidden_layer_neurons, n_layers=number_of_hidden_layers,\n",
    "                                 hl_act_func=hidden_layer_act_function,\n",
    "                                 ol_act_func=output_layer_act_function,\n",
    "                                 loss_func=loss_function,\n",
    "                                 optimizer=optimizer,\n",
    "                                 metrics=metrics,\n",
    "                                 name='model_fold{}_init{}'.format(idx+1, init+1)\n",
    "                                )\n",
    "        # fit he model using the data\n",
    "        train_evo = model.fit(X_norm[train_id], y_sparse[train_id],\n",
    "                             batch_size=batch_size, epochs=n_epochs,\n",
    "                             callbacks=callbacks,\n",
    "                             validation_data=(X_norm[test_id], y_sparse[test_id]),\n",
    "                             verbose=0)\n",
    "        # evaluate the model\n",
    "        score = model.evaluate(X_norm[test_id], y_sparse[test_id])\n",
    "    print('~~~~~~~~~~ End the training in Fold ~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'sparse_top_k_categorical_accuracy', 'categorical_accuracy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5880674123764038,\n",
       " 1.583601713180542,\n",
       " 1.5788795948028564,\n",
       " 1.5736991167068481,\n",
       " 1.5688117742538452,\n",
       " 1.5637754201889038,\n",
       " 1.5587480068206787,\n",
       " 1.5537278652191162,\n",
       " 1.548530101776123,\n",
       " 1.5433226823806763]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evo.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5433226823806763, 1.0, 0.53333336114883423]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
